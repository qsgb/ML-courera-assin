---
title: Machine Learning of Self Movement 
  
author: Jian LIU
output:
  html_document:
    fig_height: 9
    fig_width: 9
---

## Introduction  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement-a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  

In this project, we will use data from Human Activity Recognition project which contains accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise.  

## Data Preprocessing  
```{r, load package, cache = TRUE, echo=FALSE, results= "hide"}
library(caret)
library(randomForest)
```

The data is dowload from the cousera Practical Machine Learning course website([pml-training](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) and [pml-testing](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)). These data come from the [Human Activity Recognition project](http://groupware.les.inf.puc-rio.br/har).They are read as trianRaw and testRaw in R. There are 160 variables in the datasets, the variable "outcome"" was chosen to be predicted.

```{r, readata, cache = TRUE}
trainRaw <- read.csv("pml-training.csv",header = TRUE)
testRaw <- read.csv("pml-testing.csv",header = TRUE)
dim(trainRaw)
dim(testRaw)
```

There are some column contains only NA, so we first remove them. The labal "X", "timesstamp" and "window" paramaters are not related to outcome thus the columns containing these terms were removed. Then the non-numeric columns were also removed, but the outcome column was kept for prediction. The final datasets for training and testing both have only 53 variables.

```{r, cleandata, cache = TRUE}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0] 
classe <- trainRaw$classe
Index <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !Index]
train <- trainRaw[, sapply(trainRaw, is.numeric)]
train$classe <- classe
Indext <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !Indext]
test <- testRaw[, sapply(testRaw, is.numeric)]
dim(train)
dim(test)
```  

## Machine learning

Here we appied some maching learning methods on the cleaned dataset.

### Slice the data

First, we splitted the cleaned training set into a pure training data set (75%) and a validation data set (25%). 

```{r, split, cache = T}
set.seed(123) 
inTrain <- createDataPartition(train$classe, p=0.75, list=F)
trainData <- train[inTrain, ]
vadData <- train[-inTrain, ]
```

### Random forest

We applied **Random Forest** algorithm to fit a predictive model. We spicified  **5-fold cross validation** when performing the algorithm. THe final model was tested by the validation set to measure the accuracy of the model.

```{r, rf, cache = T}
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=trainData, method="rf", trControl=control, ntree=250)
predict<- predict(model, vadData)
confusionMatrix(vadData$classe, predict)
```

We found the estimated accuracy of this model to the validation set is **99.29%**, thus the estimated out-of-sample error is **0.71%** for this method.

## Predicting for Test Data Set

Finally, we applied the model to the supplied testing data set downloaded from the data source. In the data processing session, the testing data have been subjected to  the same process of trainning data and the final set is named as "test". We subjected this set to the final model. The test set contains the id number as the the last column, it was removed during the prediction. 

```{r, cache = T}
predict(model, test[,-53])
```  

